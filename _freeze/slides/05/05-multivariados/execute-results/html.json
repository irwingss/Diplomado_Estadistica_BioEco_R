{
  "hash": "6b6979776963718ee47e602fcbe868d5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Técnicas multivariadas\nsubtitle: Módulo 9\ntitle-slide-attributes:\n  data-background-image: ../bg4.png\n  data-background-size: cover\n  data-slide-number: default\nformat:\n  revealjs:\n    mathjax: default\n    theme:\n     - \"default\"\n     - \"../slides.scss\"\n    width: \"1600\"\n    height: \"900\"\n    slide-number: true\n    highlight-style: atom-one\n    incremental: true   \n    chalkboard: \n       theme: chalkboard\n       chalk-effect: 0.1\n       chalk-width: 5\n       boardmarker-width: 7\nfilters:\n  - shinylive\ncache: true\n---\n\n::: {.cell}\n\n:::\n\n\n\n# Objetivos del módulo {background-image=\"../bg8.png\"}\n\n::: incremental\n- Comprender los fundamentos de los análisis multivariados.\n- Elegir adecuadamente la técnica multivariada según sea el caso aplicativo.\n- Interpretar de manera efectiva los resultados de las técnicas multivariantes.\n- Producir gráficos de alta calidad como parte de resultados analíticos multivariados.\n- Desarrollar scripts de técnicas multivariadas de manera efectiva con sintaxis de R.\n:::\n\n# Introducción\n\n## Temario del módulo\n\n::: incremental\n- Conceptos y aplicaciones de las técnicas multivariadas\n- Matrices de datos multidimensionales.\n- Canónico vs no canónico.\n- ¿Qué técnicas existen?\n- Reducción de dimensiones: PCA.\n- Análisis de correspondencia CA.\n- PCoA o MDS.\n- NMDS\n- Agrupamiento no jerárquico: Análisis cluster.\n- Árboles de agrupamiento jerárquico.\n- El lado canónico: RDA y CCA.\n:::\n\n# 1. Estadística Multivariada\n\n## ¿Cómo resuelves estas preguntas…?\n\n::::{.columns}\n:::{.column width=\"30%\"}\n- ¿Qué variables independientes describen el comportamiento de mi variable de respuesta Z?\n- ¿Cómo cambia el valor de mi variable Z en función de los valores de A, B y C?\n- ¿Cuál es el efecto que tiene A, B y C sobre la variable Z?\n:::\n\n:::{.column width=\"70%\"}\n:::{.fragment}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Tecnicas de Ordenamiento2.png)\n:::\n:::\n\n\n:::\n:::\n::::\n\n## ¿Y estas otras preguntas…?\n\n::::{.columns}\n:::{.column width=\"30%\"}\n- ¿Cómo se agrupan mis unidades de muestreo en función de sus características?\n- ¿Qué variables independientes son importantes para separar/discriminar las tres categorías de la variable dependiente A?\n- ¿Cuál es el efecto que tienen las variables independientes A, B y C sobre las dependientes X, Y y Z?\n:::\n\n:::{.column width=\"70%\"}\n:::{.fragment}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Tecnicas de Ordenamiento.png)\n:::\n:::\n\n\n:::\n:::\n::::\n\n## {}\n\n::: callout-tip\nSegún Hanley (1983) “... el término\nmultivariado viene a describir una\ncolección de técnicas estadísticas para\nlidiar con diversas variables en un solo\nanálisis…”\n:::\n\n- Término **multivariado** y **multivariable**.\n- ¿Regresiones múltiples?\n- No siempre se tiene variable de respuesta.\n- A veces nuestra *variable de respuesta* es en realidad toda una **matriz de respuesta**.\n\n## Paradoja de Simpson\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/paradoja_simpson.png)\n:::\n:::\n\n\n\n## Paradoja de Simpson\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/paradoja_simpson_2.png)\n:::\n:::\n\n\n\n\n## Comprendamos las técnicas multivariadas {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Tecnicas de Ordenamiento3.png)\n:::\n:::\n\n\n\n## Matrices de datos multidimensionales\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Tecnicas de Ordenamiento4.png)\n:::\n:::\n\n\n## Métodos de distancias distancias 1\n\n::::{.columns}\n:::{.column}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/distancias.png)\n:::\n:::\n\n\n:::\n\n:::{.column}\n:::{.fragment}\n\n<br>\n\n#### Distancias para datos continuos\n- Distancia Euclidiana\n- Distancia de Manhattan y Minkowski\n- Distancia de Mahalanobis\n\n#### Distancias para datos proporcionales\n- Distancia de Hellinger\n- Distancia Chi-cuadrado\n- Distancia de Canberra\n- Distancia de Chord\n\n#### Distancias mixtas\n- Distancia de Gower\n:::\n:::\n::::\n\n## Métodos de distancias distancias 2\n\n::::{.columns}\n:::{.column}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/distancias.png)\n:::\n:::\n\n\n:::\n\n:::{.column}\n:::{.fragment}\n\n<br>\n\n#### Distancias para datos de presencia/ausencia\n- Distancia de Jaccard\n- Distancia de Sorensen\n- Distancia Binaria (o Dice)\n- Distancia Raup-Crick\n\n#### Distancias para datos de abundancia\n- Distancia de Bray-Curtis\n- Distancia de Morisita-Horn\n- Distancia de Kulczynski\n- Distancia de Whittaker\n\n:::\n:::\n::::\n\n## ¿Para qué sirven estos métodos de distancias? {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Tecnicas de Ordenamiento6.png)\n:::\n:::\n\n\n\n:::footer\n[https://github-wiki-see.page/](https://github-wiki-see.page/m/Statistics-and-Machine-Learning-with-R/Statistical-Methods-and-Machine-Learning-in-R/wiki/Permutational-Multivariate-Analysis-of-Variance)\n:::\n\n## ¿Para qué sirven estos métodos de distancias? {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/hierarchical holzhauer et al 2022.png)\n:::\n:::\n\n\n\n:::footer\n<https://www.sciencedirect.com/science/article/pii/S096456912100421X?via%3Dihub>\n:::\n\n## Transformaciones {}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/paper legendre.png){fig-align='center'}\n:::\n:::\n\n\n\n:::footer\n<https://link.springer.com/article/10.1007/s004420100716>\n:::\n\n## ¿Cómo influencian las transformaciones a las distancias?\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/Transformaciones.png){fig-align='center'}\n:::\n:::\n\n\n\n## Distancia Euclidiana\n\n$$\nd_{ij} = \\sqrt{\\sum_{k=1}^p (x_{ik} - x_{jk})^2}\n$$\n\n- **Ventajas**: Intuitiva y fácil de calcular.\n- **Limitaciones**: Sensible a escalas y unidades. Es necesario estandarizar las variables si tienen magnitudes diferentes.\n- **Aplicaciones**: Común en técnicas como análisis de conglomerados.\n\n## Comprendamos la distancia euclidiana {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Tecnicas de Ordenamiento5.png)\n:::\n:::\n\n\n## El problema de los dobles ceros en distancias euclidianas {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/paper legendre 2.png)\n:::\n:::\n\n\n\n## Distancia de Manhattan (City Block)\n\n$$\nd_{ij} = \\sum_{k=1}^p |x_{ik} - x_{jk}|\n$$\n\n- **Ventajas**: Menos sensible a valores extremos que la distancia euclidiana.\n- **Aplicaciones**: Usada en contextos donde las distancias son lineales, como en ciudades con una estructura en cuadrícula.\n- **Ejemplo**: Común en problemas urbanos y redes logísticas.\n\n## Distancia de Mahalanobis\n\n$$\nd_{ij} = \\sqrt{(x_i - x_j)^T S^{-1} (x_i - x_j)}\n$$\n\n- **Ventajas**: Considera la estructura de correlación entre variables.\n- **Limitaciones**: Requiere que el número de observaciones sea mayor que el número de variables para que $S^{-1}$ exista.\n- **Aplicaciones**: Clasificación y análisis discriminante.\n\n## Distancia de Hellinger\n\n$$\nd_{ij} = \\sqrt{\\sum_{k=1}^p \\left(\\sqrt{\\frac{x_{ik}}{\\sum_{k=1}^p x_{ik}}} - \\sqrt{\\frac{x_{jk}}{\\sum_{k=1}^p x_{jk}}}\\right)^2}\n$$\n\n- **Descripción**: Una medida basada en raíces cuadradas de proporciones, que minimiza la influencia de valores extremos.\n- **Ventajas**:\n  - Reduce el impacto de valores pequeños y ceros.\n  - Conserva la estructura de similitud entre observaciones.\n- **Aplicaciones**:\n  - Común en ecología para analizar composiciones de comunidades.\n  - Análisis de datos de conteo y proporciones.\n- **Nota**: Proporciona resultados similares a la transformación logarítmica, pero es más adecuada para datos con ceros.\n\n## Distancia Chi-cuadrado\n\n$$\nd_{ij} = \\sqrt{\\sum_{k=1}^p \\frac{(x_{ik} - x_{jk})^2}{x_{ik} + x_{jk}}}\n$$\n\n- **Descripción**: Mide la disimilitud entre perfiles de fila o columna en tablas de contingencia.\n- **Ventajas**: Resalta las diferencias en proporciones relativas más que en valores absolutos.\n- **Limitaciones**: Puede ser sensible a ceros en los datos.\n- **Aplicaciones**: \n  - Comparar distribuciones categóricas.\n  - Análisis de correspondencias en datos de conteo.\n\n\n## Distancia de Chord\n\n$$\nd_{ij} = \\sqrt{\\sum_{k=1}^p \\left(\\frac{x_{ik}}{\\sqrt{\\sum_{k=1}^p x_{ik}^2}} - \\frac{x_{jk}}{\\sqrt{\\sum_{k=1}^p x_{jk}^2}}\\right)^2}\n$$\n\n- **Descripción**: Calcula la disimilitud entre dos vectores normalizados por su longitud, proyectándolos en una hiperesfera unitaria.\n- **Ventajas**:\n  - Insensible a las diferencias en magnitud entre vectores, ya que trabaja con datos normalizados.\n  - Conserva la estructura de similitud angular entre observaciones.\n- **Aplicaciones**:\n  - Composición de comunidades en ecología.\n  - Análisis de perfiles normalizados, como datos espectrales.\n\n\n## Distancia de Canberra\n\n$$\nd_{ij} = \\sum_{k=1}^p \\frac{|x_{ik} - x_{jk}|}{|x_{ik}| + |x_{jk}|}\n$$\n\n- **Ventajas**: Da más peso a pequeñas diferencias cuando los valores son cercanos a cero.\n- **Aplicaciones**: Comparaciones sensibles a las escalas.\n- **Nota**: Es útil en análisis de proporciones (coberturas, abundancias relativas) o datos ambientales con valores pequeños.\n\n## Distancia de Gower\n\n$$\nd_{ij} = \\frac{\\sum_{k=1}^p w_k \\cdot d_{ijk}}{\\sum_{k=1}^p w_k}\n$$\n\n- **Aplicaciones**: Análisis de datos mixtos.\n- **Ventajas**: Flexibilidad para trabajar con variables de diferente naturaleza (numéricas, categóricas, etc.).\n- **Nota**: Los pesos $w_k$ pueden ajustarse según la relevancia de cada variable.\n\n## Distancia de Jaccard\n\n$$\nd_{ij} = 1 - \\frac{|A \\cap B|}{|A \\cup B|}\n$$\n\n- **Aplicaciones**: Compara similitudes entre conjuntos o matrices de presencia-ausencia.\n- **Ventajas**: Ignora los ceros comunes (ausencias compartidas).\n- **Ejemplo**: Usado en análisis de datos binarios, como en matrices de ocurrencia.\n\n## Distancia de Sorensen\n\n$$\nd_{ij} = 1 - \\frac{2 |A \\cap B|}{|A| + |B|}\n$$\n\n- **Descripción**: Mide la disimilitud entre dos conjuntos basándose en su intersección, **dando más peso a las coincidencias**.\n- **Ventajas**:\n  - **Más sensible a la coincidencia** entre conjuntos que la distancia de Jaccard.\n  - Ignora los ceros comunes (ausencias compartidas).\n- **Aplicaciones**:\n  - Comparación de comunidades ecológicas (presencia/ausencia de especies).\n  - Análisis de similitud en datos binarios.\n- **Ejemplo**: Usado en análisis de datos binarios, como en matrices de ocurrencia.\n\n## Distancia Binaria (o Dice)\n\n$$\nd_{ij} = 1 - \\frac{2 |A \\cap B|}{|A| + |B|}\n$$\n\n- **Descripción**: Similar a la distancia de Jaccard, pero **da más peso a la coincidencia**.\n- **Ventajas**:\n  - Más sensible a especies compartidas que Jaccard.\n- **Aplicaciones**:\n  - Análisis de datos de presencia/ausencia.\n  - Comparaciones en ecología basadas en ocurrencias.\n\n## Distancia Raup-Crick\n\n$$\nd_{ij} = P(\\text{observado} \\leq \\text{simulado})\n$$\n\n- **Descripción**: Una medida probabilística que compara la similitud observada entre dos comunidades con la esperada bajo una distribución aleatoria.\n- **Ventajas**:\n  - Ajusta las comparaciones considerando la riqueza de las comunidades.\n  - No depende únicamente del número total de especies compartidas.\n- **Aplicaciones**:\n  - Evaluación de similitudes en datos de presencia/ausencia.\n  - Identificación de patrones ecológicos no explicados por el azar (La (dis)similitud observada es mayor de lo que se esperaría por azar.)\n  - Se restringe de 0 a 1, por lo que se puede hablar de **porcentaje de disimilitud**.\n  - Valores de 0 es similitud perfecta. Valores de 1 es totalmente disimil.\n\n\n## Distancia de Bray-Curtis\n\n$$\nd_{ij} = \\frac{\\sum_{k=1}^p |x_{ik} - x_{jk}|}{\\sum_{k=1}^p (x_{ik} + x_{jk})}\n$$\n\n- **Aplicaciones**: Común en ecología para comparar comunidades biológicas.\n- **Ventajas**: Insensible a ceros comunes en las observaciones. Se restringe de 0 a 1, por lo que se puede hablar de **porcentaje de disimilitud**.\n- **Uso típico**: Comparar similitudes entre especies o comunidades.\n\n## Distancia de Morisita-Horn\n\n$$\nd_{ij} = 1 - \\frac{2 \\sum_{k=1}^p x_{ik} x_{jk}}{\\left(\\frac{\\sum_{k=1}^p x_{ik}^2}{N_i}\\right) + \\left(\\frac{\\sum_{k=1}^p x_{jk}^2}{N_j}\\right)}\n$$\n\nDonde $N_i = \\sum_{k=1}^p x_{ik}$ y $N_j = \\sum_{k=1}^p x_{jk}$.\n\n- **Descripción**: Basada en la abundancia relativa, esta métrica es menos sensible a especies raras y **más enfocada en especies dominantes**.\n- **Ventajas**:\n  - Insensible al tamaño de la muestra.\n  - Focalizada en especies con abundancias altas.\n- **Aplicaciones**:\n  - Comparación de comunidades dominadas por pocas especies.\n  - Análisis de datos de conteos en ecología.\n  \n## Distancia de Kulczynski\n\n$$\nd_{ij} = 1 - \\frac{\\sum_{k=1}^p \\min(x_{ik}, x_{jk})}{\\frac{1}{2} \\left(\\sum_{k=1}^p x_{ik} + \\sum_{k=1}^p x_{jk} \\right)}\n$$\n\n- **Descripción**: Mide la proporción de especies compartidas entre dos comunidades, ponderada por la abundancia relativa.\n- **Ventajas**:\n  - Sensible a diferencias en composiciones abundantes.\n  - Permite identificar similitudes en especies dominantes.\n- **Aplicaciones**:\n  - Comparación de comunidades ecológicas basadas en abundancia.\n  - Identificación de patrones de similitud entre hábitats.\n\n## Distancia de Whittaker\n\n$$\nd_{ij} = 1 - \\frac{\\sum_{k=1}^p \\min(x_{ik}, x_{jk})}{\\sum_{k=1}^p x_{ik}}\n$$\n\n- **Descripción**: Mide la proporción de especies compartidas en relación con la comunidad menos diversa.\n- **Ventajas**:\n  - Focalizada en diferencias relativas.\n- **Aplicaciones**:\n  - Comparación de comunidades de diferentes tamaños.\n\n## Equivalencia de las transformaciones {}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/paper legendre 3.png){fig-align='center'}\n:::\n:::\n\n\n\n:::footer\n<https://link.springer.com/article/10.1007/s004420100716>\n:::\n\n## Efecto de la transformación sobre las distancias {}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/paper legendre 4.png){fig-align='center'}\n:::\n:::\n\n\n\n:::footer\n<https://link.springer.com/article/10.1007/s004420100716>\n:::\n\n## Efecto de la transformación sobre las distancias {}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/paper legendre 5.png){fig-align='center'}\n:::\n:::\n\n\n\n:::footer\n<https://link.springer.com/article/10.1007/s004420100716>\n:::\n\n# 2. Técnicas Multivariadas\n\n## Canónico vs No Canónico {.center}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"jrpjenlzph\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#jrpjenlzph table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#jrpjenlzph thead, #jrpjenlzph tbody, #jrpjenlzph tfoot, #jrpjenlzph tr, #jrpjenlzph td, #jrpjenlzph th {\n  border-style: none;\n}\n\n#jrpjenlzph p {\n  margin: 0;\n  padding: 0;\n}\n\n#jrpjenlzph .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 25px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#jrpjenlzph .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#jrpjenlzph .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#jrpjenlzph .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#jrpjenlzph .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jrpjenlzph .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jrpjenlzph .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jrpjenlzph .gt_col_heading {\n  color: #FFFFFF;\n  background-color: #0013FE;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#jrpjenlzph .gt_column_spanner_outer {\n  color: #FFFFFF;\n  background-color: #0013FE;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#jrpjenlzph .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#jrpjenlzph .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#jrpjenlzph .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#jrpjenlzph .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#jrpjenlzph .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#jrpjenlzph .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#jrpjenlzph .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#jrpjenlzph .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#jrpjenlzph .gt_row {\n  padding-top: 10px;\n  padding-bottom: 10px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#jrpjenlzph .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jrpjenlzph .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#jrpjenlzph .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#jrpjenlzph .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#jrpjenlzph .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jrpjenlzph .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#jrpjenlzph .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#jrpjenlzph .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jrpjenlzph .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jrpjenlzph .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#jrpjenlzph .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jrpjenlzph .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#jrpjenlzph .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jrpjenlzph .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jrpjenlzph .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jrpjenlzph .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jrpjenlzph .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jrpjenlzph .gt_left {\n  text-align: left;\n}\n\n#jrpjenlzph .gt_center {\n  text-align: center;\n}\n\n#jrpjenlzph .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#jrpjenlzph .gt_font_normal {\n  font-weight: normal;\n}\n\n#jrpjenlzph .gt_font_bold {\n  font-weight: bold;\n}\n\n#jrpjenlzph .gt_font_italic {\n  font-style: italic;\n}\n\n#jrpjenlzph .gt_super {\n  font-size: 65%;\n}\n\n#jrpjenlzph .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#jrpjenlzph .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#jrpjenlzph .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#jrpjenlzph .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#jrpjenlzph .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#jrpjenlzph .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#jrpjenlzph .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#jrpjenlzph .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#jrpjenlzph div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n\n.gt_table tr:hover td {\n  background-color: #E6F3FF !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" style=\"font-weight: bold;\" scope=\"col\" id=\"Ordenamiento sin restricciones - ML no supervisado\">Ordenamiento sin restricciones - ML no supervisado</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" style=\"font-weight: bold;\" scope=\"col\" id=\"Ordenamiento con restricciones - ML supervisado\">Ordenamiento con restricciones - ML supervisado</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Ordenamiento sin restricciones - ML no supervisado\" class=\"gt_row gt_center\">Métodos interdependientes</td>\n<td headers=\"Ordenamiento con restricciones - ML supervisado\" class=\"gt_row gt_center\">Métodos dependientes</td></tr>\n    <tr><td headers=\"Ordenamiento sin restricciones - ML no supervisado\" class=\"gt_row gt_center gt_striped\">Análisis No Canónico</td>\n<td headers=\"Ordenamiento con restricciones - ML supervisado\" class=\"gt_row gt_center gt_striped\">Análisis Canónico</td></tr>\n    <tr><td headers=\"Ordenamiento sin restricciones - ML no supervisado\" class=\"gt_row gt_center\">1 grupo de variables.</td>\n<td headers=\"Ordenamiento con restricciones - ML supervisado\" class=\"gt_row gt_center\">2 grupos de variables: X e Y.</td></tr>\n    <tr><td headers=\"Ordenamiento sin restricciones - ML no supervisado\" class=\"gt_row gt_center gt_striped\">Permiten describir.</td>\n<td headers=\"Ordenamiento con restricciones - ML supervisado\" class=\"gt_row gt_center gt_striped\">Permiten predecir.</td></tr>\n    <tr><td headers=\"Ordenamiento sin restricciones - ML no supervisado\" class=\"gt_row gt_center\">No buscan definir la relación entre variables dependientes o independientes.</td>\n<td headers=\"Ordenamiento con restricciones - ML supervisado\" class=\"gt_row gt_center\">Buscan definir la relación entre variables dependientes o independientes.</td></tr>\n    <tr><td headers=\"Ordenamiento sin restricciones - ML no supervisado\" class=\"gt_row gt_center gt_striped\">Busca observar patrones de agrupamiento en los datos.</td>\n<td headers=\"Ordenamiento con restricciones - ML supervisado\" class=\"gt_row gt_center gt_striped\">Busca definir la causa de los patrones de agrupamiento.</td></tr>\n    <tr><td headers=\"Ordenamiento sin restricciones - ML no supervisado\" class=\"gt_row gt_center\">No hay contraste de hipótesis.</td>\n<td headers=\"Ordenamiento con restricciones - ML supervisado\" class=\"gt_row gt_center\">Hay contraste de hipótesis.</td></tr>\n    <tr><td headers=\"Ordenamiento sin restricciones - ML no supervisado\" class=\"gt_row gt_center gt_striped\">Son considerados métodos de agrupación.</td>\n<td headers=\"Ordenamiento con restricciones - ML supervisado\" class=\"gt_row gt_center gt_striped\">Son considerados métodos de clasificación.</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n## Clasificación de técnicas multivariadas {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Diapositiva1.PNG)\n:::\n:::\n\n\n\n## {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Diapositiva2.PNG)\n:::\n:::\n\n\n\n## {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Diapositiva3.PNG)\n:::\n:::\n\n\n\n## {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Diapositiva4.PNG)\n:::\n:::\n\n\n\n## {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Diapositiva5.PNG)\n:::\n:::\n\n\n\n## {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Diapositiva6.PNG)\n:::\n:::\n\n\n\n## {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Diapositiva7.PNG)\n:::\n:::\n\n\n\n\n## Técnicas No Canónicas 1\n\n- Análisis de Componentes Principales: [PCA](https://rpubs.com/cristina_gil/pca) + [tb-PCA](https://www.davidzeleny.net/anadat-r/doku.php/en:pca)\n- Análisis Factorial: [FA](https://rpubs.com/marcelo-chavez/multivariado_1)\n- Análisis de Múltiples Factores: [MFA](https://rpubs.com/Alvarofelipes/1041897)\n- Análisis Factorial Confirmatorio: [AFC](https://rpubs.com/FedeVillalba/979441) \n- Análisis de Correspondencia: [CA](https://www.davidzeleny.net/anadat-r/doku.php/en:ca_dca)\n- Análisis de Correspondencia sin Tendencia: [DECORANA](https://www.davidzeleny.net/anadat-r/doku.php/en:ca_dca_examples)\n- Análisis de Correspondencia Múltiple: [MCA](https://rpubs.com/gustavomtzv/1042047)\n- Análisis de Coordenadas Principales: [MDS](https://rpubs.com/Hasantha_APS_1701/917047) o [PCoA](https://www.davidzeleny.net/anadat-r/doku.php/en:pcoa_nmds)\n- Escalamiento Multidimensional No Métrico: [NMDS](https://www.davidzeleny.net/anadat-r/doku.php/en:pcoa_nmds)\n- Agrupamiento [Jerárquico](https://rpubs.com/Alvarofelipes/1041879) \n- Agrupamiento No Jerárquico [K-means](https://rpubs.com/anagalvan/informe4), [K-medioids](https://rpubs.com/Ernestodaspferd/boffpapitolinlin)\n- Análisis Multivariado de Varianza Permutacional [PERMANOVA*](https://rpubs.com/DKCH2020/587758)\n- Análisis de similaridades [ANOSIM*](https://rpubs.com/aafernandez1976/ANOSIMyNMDS)\n\n## Técnicas No Canónicas 2\n\n- Escalamiento de T-distribución Estocástica Vecinos: [t-SNE](https://rpubs.com/TusVasMit/T-SNEExploration)\n- t-SNE optimizado por [LargeVis](https://arxiv.org/abs/1602.00370)\n- Optimización de Proximidad de Vecinos Uniforme: [UMAP](https://ar5iv.labs.arxiv.org/html/1802.03426)\n- Modelos de Mezcla Gaussianos [(Gaussian Mixture Models)](https://www.mdpi.com/2072-4292/13/10/1989): [GMM](https://rpubs.com/dapivei/705612)\n- Análisis de Vectores de Soporte: [SVM](https://rpubs.com/joaquin_ar/267926)\n- Fuzzy C-Means: [FCM](https://rpubs.com/rahulSaha/Fuzzy-CMeansClustering)\n- Gustafson-Kessel Algorithm (Mahalanobis): [GKA](https://www.rpubs.com/anablake/gustafson-kessel)\n- Otros [métodos Fuzzy](https://www.janbasktraining.com/tutorials/fuzzy-clustering/)\n\n## Ténicas Canónicas\n\n- Análisis de Redundancia: [RDA](https://rpubs.com/ericata/ecoinformatics)\n- Análisis de Correspondencia Canónica: [CCA](https://rpubs.com/JairoAyala/CCA)\n- Análisis de Correlaciones Canónicas: [CCorA](https://rpubs.com/marv/1045103)\n- Análisis Discriminante Lineal: [LDA](https://rpubs.com/joaquin_ar/233932)\n- Análisis Discriminante Cuadrático: [QDA](https://rpubs.com/joaquin_ar/233932)\n- Análisis Multivariado de Varianza: [MANOVA](https://rpubs.com/marv/1045106)\n- Análisis de Procrustes: [PA](https://john-quensen.com/tutorials/procrustes-analysis/)\n- Modelos de Ecuaciones Estructurales: [SEM](https://rpubs.com/Agrele/SEM)\n\n# 3. Estadística Multivariada No Canónica\n\n## Árboles Jerárquicos\n\n:::{.columns}\n:::{.column width=\"40%\"}\n- Es una herramienta para evidenciar estructuras de agrupamiento en los datos.\n\n#### Procedimiento:\n1. Cada fila es un cluster.\n2. Se crean clusters de dos en dos en base a sus distancias.\n3. Estos grupos se agregan usando método de aglomeración.\n4. Se repite el proceso hasta aglomerar todos los grupos.\n:::\n\n:::{.column width=\"60%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/NOMBRE QUE DESEES.png){fig-align='center' width=90%}\n:::\n:::\n\n\n:::\n::::\n\n## {}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/jerarquico.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n## Métodos de aglomeración `hclust()`\n\n:::{.columns}\n:::{.column width=\"40%\"}\n- **Single linkage (a)**: es la distancia más corta entre dos puntos en ambos grupos.\n- **Complete linkage (b)**: Es lo opuesto al eslabonamiento simple. Es la distancia más larga entre dos puntos en ambos grupos.\n- **Average linkage o UPGMA (c)**: es la distancia promedio entre cada punto en un grupo a cada punto en el otro grupo.\n- **Centroid**: la distancia entre el punto central de un grupo y el punto central del otro grupo.\n:::\n\n:::{.column width=\"60%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/aglomeracion.png){fig-align='center' width=90%}\n:::\n:::\n\n\n:::\n::::\n\n## Métodos de aglomeración `hclust()`\n\n:::{.columns}\n:::{.column width=\"40%\"}\n- **Método de Ward (Least Squares)**: una combinación de métodos promedio y centroide. La distancia dentro del conglomerado se calcula determinando el punto central del conglomerado y la distancia de las observaciones desde el centro. Al\nintentar fusionar dos conglomerados, se encuentra la distancia entre los conglomerados y se fusionan los conglomerados cuya varianza es menor en comparación con la otra combinación.\n:::\n\n:::{.column width=\"60%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/aglomeracion 2.png){fig-align='center' width=90%}\n:::\n:::\n\n\n:::\n::::\n\n## {}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/aglomeracion 3.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Reducción de dimensionalidad: PCA\n\n:::{.columns}\n:::{.column width=\"30%\"}\n- Usualmente inadecuado para datas de especies.\n- Adecuado para data ambiental.\n- Reduce la dimensiones de la base de datos a 2 variables nuevas (componentes principales).\n- Los CP son combinaciones lineales de todas las variables de la tabla.\n:::\n\n:::{.column width=\"70%\"}\n:::{.fragment}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/pca.gif){fig-align='center' width=50%}\n:::\n:::\n\n\n\n- Componentes principales que **MAXIMIZAN la variabilidad**.\n\n:::\n:::\n::::\n\n## PCA y regresión lineal no abordan la minimización de errores de la misma manera{}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/PCA vs reg linea.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Procedimiento interno del PCA: 1 y 2\n\n:::{.columns}\n:::{.column width=\"30%\"}\n#### Decomposición de varianza\n1. **Estandarizar la base de datos ( μ=0, σ2=1).**\n2. **Cálculo de las matrices de covarianzas.**\n3. Cálculo de los eigenvectores y eigenvalores.\n4. Reordenamiento de los eigenvalores y eigenvectores.\n5. Reproyectar los datos en los ejes principales\n\n:::\n\n:::{.column width=\"70%\"}\n:::{.fragment}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/matrices de cov o corr.png){width=80%}\n:::\n:::\n\n\n:::\n:::\n::::\n\n## Procedimiento interno del PCA: 3\n\n:::{.columns}\n:::{.column width=\"30%\"}\n#### Decomposición de varianza\n1. Estandarizar la base de datos ( μ=0, σ2=1).\n2. Cálculo de las matrices de covarianzas.\n3. **Cálculo de los eigenvectores y eigenvalores.**\n4. Reordenamiento de los eigenvalores y eigenvectores.\n5. Reproyectar los datos en los ejes principales\n\n:::\n\n:::{.column width=\"70%\"}\n:::{.fragment}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/eigenvals.png){width=80%}\n:::\n:::\n\n\n:::\n:::\n::::\n\n## Procedimiento interno del PCA: 4\n\n:::{.columns}\n:::{.column width=\"30%\"}\n#### Decomposición de varianza\n1. Estandarizar la base de datos ( μ=0, σ2=1).\n2. Cálculo de las matrices de covarianzas.\n3. Cálculo de los eigenvectores y eigenvalores.\n4. **Reordenamiento de los eigenvalores y eigenvectores.**\n5. Reproyectar los datos en los ejes principales\n\n:::\n\n:::{.column width=\"70%\"}\n:::{.fragment}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/ordenamiento de cp.png){width=80%}\n:::\n:::\n\n\n:::\n:::\n::::\n\n\n## Procedimiento interno del PCA: 5\n\n:::{.columns}\n:::{.column width=\"30%\"}\n#### Decomposición de varianza\n1. Estandarizar la base de datos ( μ=0, σ2=1).\n2. Cálculo de las matrices de covarianzas.\n3. Cálculo de los eigenvectores y eigenvalores.\n4. Reordenamiento de los eigenvalores y eigenvectores.\n5. **Reproyectar los datos en los ejes principale**\n\n:::\n\n:::{.column width=\"70%\"}\n:::{.fragment}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/pca biplot penguins.png){width=80%}\n:::\n:::\n\n\n:::\n:::\n::::\n\n## Tipo de matriz del PCA\n\n:::{.columns}\n:::{.column width=\"50%\"}\n\n**PCA basado en matrices de covarianzas (`scale. = FALSE`)**\n\n:::{.fragment}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/pca biplot matriz covarianzas penguins.png){width=90%}\n:::\n:::\n\n\n:::\n:::\n\n:::{.column width=\"50%\"}\n\n**PCA basado en matrices de correlaciones (`scale. = TRUE`)**\n\n:::{.fragment}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/pca biplot penguins.png){width=90%}\n:::\n:::\n\n\n:::\n:::\n::::\n\n## Caso: Palmer Penguins {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/geentoo.png){width=100%}\n:::\n:::\n\n\n\n:::footer\n<https://lauranavarroviz.wordpress.com/2020/08/01/palmer-penguins>\n:::\n\n## Caso: Palmer Penguins {}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/Tecnicas de Ordenamiento7.png){width=100%}\n:::\n:::\n\n\n\n## Leyendo el PCA \n\n:::{.columns}\n:::{.column width=\"40%\"}\n- El ángulo entre las variables indica el grado de correlación entre ellas: Correlación positiva; Correlación negativa (inversa); Nula (90°).\n- La posición de un punto (filas de la base) respeto a los vectores de las variables (columnas de la base) refleja sus relaciones.\n- Punto cerca a vector contiene altos valores de dicha variable.\n- Los puntos cercanos entre sí son más similares.\n\n:::\n\n:::{.column width=\"60%\"}\n:::{.fragment}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/pca biplot penguins.png){width=80%}\n:::\n:::\n\n\n:::\n:::\n::::\n\n## Estandarización vs Normalización\n\n::::{.columns}\n:::{.column width=\"50%\"}\n#### Normalización\n\n- Comprimir una variable para que encaje en el rango de 0 a 1. \n- También le llaman escalado de características (featuring scaling) o normalización basada en la unidad (unity-based normalization). \n- Funciona como transformación de rango, chord o hellinger.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndecostand(DF, method = \"normalization\") \n# esto es la transf. de Chord\n```\n:::\n\n\n:::\n\n:::{.column width=\"50%\"}\n#### Estandarización (centrado y escalado)\n\n- Hace que cada variable tenga promedio 0 y desviación estándar 1.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndecostand(DF, method = \"standarization\")\nscale(DF)\n```\n:::\n\n\n\n:::\n::::\n\n## Análisis de Correspondencia: CA\n\n::::{.columns}\n:::{.column width=\"40%\"}\n\n- Trabaja con matrices de contingencia entre las categorías de dos variables categóricas.\n- Permite identificar como las especies están asociadas con determinada condición del entorno (categóricas, agrupamiento).\n- Permite visualizar cómo las especies ocupan diferentes nichos en el ecosistema.\n:::\n\n:::{.column width=\"60%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/ca escenarios.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::\n::::\n\n:::footer\n[CA en diferentes escenarios simulados](https://www.nature.com/articles/s41598-021-87971-9)\n:::\n\n## Análisis de Coordenadas Principales: PCoA\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/MDS.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::footer\n<https://www.nature.com/articles/s41467-019-12500-2>\n:::\n\n## Ventajas del MDS sobre Otras Técnicas de Ordenación\n\n- **Optimización por Dimensiones Deseadas:** MDS ajusta directamente al número de dimensiones deseado.\n\n- **Cualquier distancia proyectada en un espacio euclidiano:** Proporciona una representación euclidiana de un conjunto de objetos cuya relación se mide mediante cualquier índice de disimilitud.\n\n:::callout-tip\nPara la mayoría de los datos ecológicos, la relación entre la disimilitud de los datos y la distancia de ordenación será no lineal. En consecuencia, los ecólogos prefieren el escalamiento multidimensional no métrico (NMDS).\n:::\n\n:::callout-warning\nEigenvalues negativos necesitan corregirse (Lingoes). O convertir una distancia no métrica (Bray-curtis) en una métrica (raíz cuadrada de Bray-curtis).\n:::\n\n## Comparando MDS con NMDS {}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/pcoa vs nmds.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Escalamiento Multidimensional No Métrico: NMDS\n\nEl **Escalamiento Multidimensional No Métrico (NMDS)** es una alternativa no métrica al análisis de **PCoA**. Su objetivo principal es ubicar las muestras en un espacio de ordenación de baja dimensionalidad (dos o tres ejes), de manera que las distancias euclidianas entre estas muestras correspondan a las disimilitudes representadas por el índice de disimilitud original.\n\n\n## Características Clave del NMDS\n\n- **Uso de Cualquier Medida de Disimilitud:** Puede emplear cualquier índice de disimilitud entre muestras.\n- **Conversión de Disimilitudes en Rangos:** No utiliza los valores brutos de disimilitud, sino que los convierte en rangos para los cálculos.\n- **Algoritmo Iterativo.**\n\n## Comparación con PCoA\n\n- **NMDS:**\n  - Método iterativo con posibles soluciones variables en cada ejecución.\n  - El número de ejes es especificado por el usuario.\n  - Optimiza la representación en el número de dimensiones deseado.\n\n- **PCoA:**\n  - Solución analítica única.\n  - El número de ejes depende de las propiedades del conjunto de datos.\n  - No permite especificar directamente el número de dimensiones.\n\n::: callout-tip\n**Nota:** El NMDS es especialmente adecuado para datos ecológicos donde la relación entre la disimilitud y la distancia de ordenación es no lineal, por lo que es preferido eh ecología.\n:::\n\n## Ventajas del NMDS\n\n- **Flexibilidad con Datos No Lineales:** Ideal para representar relaciones complejas en datos ecológicos.\n- **Adaptabilidad Dimensional:** Permite especificar y optimizar el número de dimensiones para la ordenación.\n- **Mejor Ajuste de Disimilitudes:** Al usar rangos, capta más efectivamente las relaciones entre muestras.\n\n## Diagrama de Shepard: gráfico de estrés\n\n:::{.columns}\n:::{.column width=\"30%\"}\n- El Diagrama de Shepard representa la correlación que existe entre la disimilaridad observada y la distancia medida en el ordenamiento (NMDS).\n- Si ambos son similares, esperamos un valor alto de R2.\n:::\n\n:::{.column width=\"70%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/shepard.png){width=100%}\n:::\n:::\n\n\n:::\n::::\n\n## Nivel de estrés\n\n:::{.columns}\n:::{.column width=\"30%\"}\nComo regla general, el valor del estrés del NMDS deberá ser interpretado como:\n\n- stress ≤0.05 = ideal\n- stress <0.1 & >0.05 = bueno \n- stress >0.1 & <0.2 = muy justo\n- stress >0.2 & <0.3 = sospechoso\n- stress >0.3 = ordenamiento arbitrario\n\n:::\n\n:::{.column width=\"70%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/nmds2.png){fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n::::\n\n## {}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/NMDS vs MDS.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::footer\n<https://www.mdpi.com/1999-4907/10/11/978>\n:::\n\n## {}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/soil.jpg){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::footer\n<https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0093445>\n:::\n\n## {}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/nmds y density function.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::footer\n<https://www.mdpi.com/2673-6004/3/4/26>\n:::\n\n## {}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/alto estres birds plants perturbaciones.png){fig-align='center' width=75%}\n:::\n:::\n\n\n\n:::footer\n<https://conbio.onlinelibrary.wiley.com/doi/abs/10.1111/cobi.13344>\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}